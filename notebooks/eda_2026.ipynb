{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c4a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import json\n",
    "import config\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b78f2b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "- [ETL](#etl)\n",
    "- [Analysis](#analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2db4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploratory Data Analysis (EDA) for Capital Crashpad Listings\n",
    "This notebook ingests, combines, and inspects Airbnb listings data across multiple quarterly snapshots.\n",
    "- Scans all available quarter directories and parses them into sortable time indices.\n",
    "- Loads each quarter’s listings_detailed.csv, annotates with quarter and index, and concatenates into a single DataFrame.\n",
    "- Provides initial checks on data shape, column consistency, and missing columns across quarters.\n",
    "- Lays the foundation for further cleaning, normalization, and time-series analysis of the DC Airbnb market.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_quarter(folder_name):\n",
    "    # e.g. '2024_sep' → '2024_Q3'\n",
    "    year, month = folder_name.split(\"_\")\n",
    "    month_to_q = {\"mar\": \"Q1\", \"jun\": \"Q2\", \"sep\": \"Q3\", \"dec\": \"Q4\"}\n",
    "    return f\"{year}_{month_to_q[month.lower()]}\"\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../resources/data/raw_data\")\n",
    "\n",
    "\n",
    "def load_quarterly_csv(filename, data_dir=DATA_DIR):\n",
    "    \"\"\"\n",
    "    Loads and annotates a quarterly CSV file from each quarter folder.\n",
    "    Adds 'quarter' and 'quarter_index' columns to each DataFrame.\n",
    "    Returns a concatenated DataFrame for all quarters.\n",
    "    \"\"\"\n",
    "    # Prepare quarter sorting\n",
    "    month_to_qnum = {\"mar\": 1, \"jun\": 2, \"sep\": 3, \"dec\": 4}\n",
    "    quarter_tuples = []\n",
    "    for p in data_dir.iterdir():\n",
    "        if p.is_dir():\n",
    "            year, month = p.name.split(\"_\")\n",
    "            qnum = month_to_qnum[month.lower()]\n",
    "            quarter_tuples.append((p.name, int(year), qnum))\n",
    "    quarters_sorted = [t[0] for t in sorted(quarter_tuples, key=lambda x: (x[1], x[2]))]\n",
    "\n",
    "    # Load and annotate each CSV\n",
    "    dfs = []\n",
    "    for i, q_folder in enumerate(quarters_sorted):\n",
    "        csv_path = data_dir / q_folder / filename\n",
    "        if not csv_path.exists():\n",
    "            print(f\"Missing: {csv_path}\")\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"quarter\"] = parse_quarter(q_folder)\n",
    "        df[\"quarter_index\"] = i\n",
    "        dfs.append(df)\n",
    "        print(f\"Loaded {q_folder} with {df.shape[0]} rows.\")\n",
    "\n",
    "    if dfs:\n",
    "        df_all = pd.concat(dfs, ignore_index=True)\n",
    "        print(\"Shape:\", df_all.shape)\n",
    "        print(\"Columns:\", df_all.columns.tolist())\n",
    "        print(\"Missing columns by quarter:\")\n",
    "        for i, q_folder in enumerate(quarters_sorted):\n",
    "            csv_path = data_dir / q_folder / filename\n",
    "            if csv_path.exists():\n",
    "                df = pd.read_csv(csv_path, nrows=1)\n",
    "                print(f\"{q_folder}: {set(df_all.columns) - set(df.columns)}\")\n",
    "        return df_all\n",
    "    else:\n",
    "        return pd.DataFrame()  # empty if nothing loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb89558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database: [('listings_long',), ('calendar_summary',), ('reviews_summary',)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Connects to a PostgreSQL database, loads schema, and provides a utility to export DataFrames.\n",
    "\n",
    "- Establishes a SQLAlchemy engine using credentials from the config file.\n",
    "- Defines a function to:\n",
    "    - Save a DataFrame as a CSV backup.\n",
    "    - Delete all rows from the target table.\n",
    "    - Load the DataFrame into the specified PostgreSQL table.\n",
    "- Loads and executes SQL schema statements from a file to create all required tables.\n",
    "- Confirms successful table creation by listing all tables in the public schema.\n",
    "\"\"\"\n",
    "\n",
    "# connect to database\n",
    "db_url = (\n",
    "    f\"postgresql://postgres:{config.password}@localhost:5432/{config.database_2026}\"\n",
    ")\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "\n",
    "# function to load table into postgres db, save backup csv\n",
    "def to_sql_and_csv(table_name, df):\n",
    "    # write to csv\n",
    "    df.to_csv(\n",
    "        f\"../resources/data/cleaned_data/2026/{table_name}_cleaned.csv\", index=False\n",
    "    )\n",
    "    # load into postgres db\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(f\"DELETE FROM {table_name}\"))\n",
    "        df.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "\n",
    "\n",
    "# load schema into postgres db\n",
    "\n",
    "# load sql schema, split by ; and run each statement\n",
    "# to create tables in postgres\n",
    "with engine.connect() as conn:\n",
    "    with open(\"./schema_2026.sql\", \"r\") as file:\n",
    "        queries = file.read().split(\";\")\n",
    "        for query in queries:\n",
    "            # strip whitespace and ignore empty queries\n",
    "            if query.strip() != \"\":\n",
    "                conn.execute(text(query))\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "# confirm tables are created\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(\n",
    "        text(\n",
    "            \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Tables in database: {result.fetchall()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4467047",
   "metadata": {},
   "source": [
    "# ETL\n",
    "- [Back to Top](#)\n",
    "\n",
    "Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc12094",
   "metadata": {},
   "source": [
    "### Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93aae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2023_jun with 6541 rows.\n",
      "Loaded 2023_sep with 6705 rows.\n",
      "Loaded 2023_dec with 6853 rows.\n",
      "Loaded 2024_mar with 6705 rows.\n",
      "Loaded 2024_jun with 4928 rows.\n",
      "Loaded 2024_sep with 5454 rows.\n",
      "Loaded 2024_dec with 5964 rows.\n",
      "Loaded 2025_mar with 6257 rows.\n",
      "Loaded 2025_jun with 6423 rows.\n",
      "Loaded 2025_sep with 6374 rows.\n",
      "Shape: (62204, 81)\n",
      "Columns: ['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name', 'description', 'neighborhood_overview', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'license', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month', 'quarter', 'quarter_index', 'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d', 'estimated_revenue_l365d']\n",
      "Missing columns by quarter:\n",
      "2023_jun: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2023_sep: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2023_dec: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2024_mar: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2024_jun: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2024_sep: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2024_dec: {'estimated_revenue_l365d', 'quarter', 'quarter_index', 'availability_eoy', 'estimated_occupancy_l365d', 'number_of_reviews_ly'}\n",
      "2025_mar: {'quarter_index', 'quarter'}\n",
      "2025_jun: {'quarter_index', 'quarter'}\n",
      "2025_sep: {'quarter_index', 'quarter'}\n"
     ]
    }
   ],
   "source": [
    "# load listings data\n",
    "listings_raw = load_quarterly_csv(\"listings_detailed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b8bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dictionary adding minimal geographic context to neighbourhood names\n",
    "\"\"\"\n",
    "\n",
    "# dict for updating neighbourhood names\n",
    "neighbourhoods_dict = {\n",
    "    \"Historic Anacostia\": \"SE Historic Anacostia\",\n",
    "    \"Edgewood, Bloomingdale, Truxton Circle, Eckington\": \"NE/NW Edgewood, Bloomingdale, Truxton Circle, Eckington\",\n",
    "    \"Capitol Hill, Lincoln Park\": \"SE Capitol Hill, Lincoln Park\",\n",
    "    \"Eastland Gardens, Kenilworth\": \"NE Eastland Gardens, Kenilworth\",\n",
    "    \"Kalorama Heights, Adams Morgan, Lanier Heights\": \"NW-mid Kalorama Heights, Adams Morgan, Lanier Heights\",\n",
    "    \"Brightwood Park, Crestwood, Petworth\": \"NW-mid Brightwood Park, Crestwood, Petworth\",\n",
    "    \"Spring Valley, Palisades, Wesley Heights, Foxhall Crescent, Foxhall Village, Georgetown Reservoir\": \"NW-far Spring Valley, Palisades, Wesley Heights, Foxhall Crescent, Foxhall Village, Georgetown Reservoir\",\n",
    "    \"Cathedral Heights, McLean Gardens, Glover Park\": \"NW-far Cathedral Heights, McLean Gardens, Glover Park\",\n",
    "    \"Lamont Riggs, Queens Chapel, Fort Totten, Pleasant Hill\": \"NE/NW Lamont Riggs, Queens Chapel, Fort Totten, Pleasant Hill\",\n",
    "    \"Shaw, Logan Circle\": \"NW-mid Shaw, Logan Circle\",\n",
    "    \"Howard University, Le Droit Park, Cardozo/Shaw\": \"NW-mid Howard University, Le Droit Park, Cardozo/Shaw\",\n",
    "    \"Takoma, Brightwood, Manor Park\": \"NW-mid Takoma, Brightwood, Manor Park\",\n",
    "    \"Colonial Village, Shepherd Park, North Portal Estates\": \"NW-mid Colonial Village, Shepherd Park, North Portal Estates\",\n",
    "    \"Dupont Circle, Connecticut Avenue/K Street\": \"NW-mid Dupont Circle, Connecticut Avenue/K Street\",\n",
    "    \"Capitol View, Marshall Heights, Benning Heights\": \"SE Capitol View, Marshall Heights, Benning Heights\",\n",
    "    \"Downtown, Chinatown, Penn Quarters, Mount Vernon Square, North Capitol Street\": \"NW-mid Downtown, Chinatown, Penn Quarters, Mount Vernon Square, North Capitol Street\",\n",
    "    \"Union Station, Stanton Park, Kingman Park\": \"NE Union Station, Stanton Park, Kingman Park\",\n",
    "    \"Georgetown, Burleith/Hillandale\": \"NW-far Georgetown, Burleith/Hillandale\",\n",
    "    \"Columbia Heights, Mt. Pleasant, Pleasant Plains, Park View\": \"NW-mid Columbia Heights, Mt. Pleasant, Pleasant Plains, Park View\",\n",
    "    \"Douglas, Shipley Terrace\": \"SE Douglas, Shipley Terrace\",\n",
    "    \"Cleveland Park, Woodley Park, Massachusetts Avenue Heights, Woodland-Normanstone Terrace\": \"NW-far Cleveland Park, Woodley Park, Massachusetts Avenue Heights, Woodland-Normanstone Terrace\",\n",
    "    \"River Terrace, Benning, Greenway, Dupont Park\": \"NE/SE River Terrace, Benning, Greenway, Dupont Park\",\n",
    "    \"Friendship Heights, American University Park, Tenleytown\": \"NW-far Friendship Heights, American University Park, Tenleytown\",\n",
    "    \"West End, Foggy Bottom, GWU\": \"NW-mid West End, Foggy Bottom, GWU\",\n",
    "    \"Southwest Employment Area, Southwest/Waterfront, Fort McNair, Buzzard Point\": \"SW Southwest Employment Area, Southwest/Waterfront, Fort McNair, Buzzard Point\",\n",
    "    \"Hawthorne, Barnaby Woods, Chevy Chase\": \"NW-far Hawthorne, Barnaby Woods, Chevy Chase\",\n",
    "    \"North Michigan Park, Michigan Park, University Heights\": \"NE North Michigan Park, Michigan Park, University Heights\",\n",
    "    \"North Cleveland Park, Forest Hills, Van Ness\": \"NW-far North Cleveland Park, Forest Hills, Van Ness\",\n",
    "    \"Brookland, Brentwood, Langdon\": \"NE Brookland, Brentwood, Langdon\",\n",
    "    \"Twining, Fairlawn, Randle Highlands, Penn Branch, Fort Davis Park, Fort Dupont\": \"SE Twining, Fairlawn, Randle Highlands, Penn Branch, Fort Davis Park, Fort Dupont\",\n",
    "    \"Mayfair, Hillbrook, Mahaning Heights\": \"NE Mayfair, Hillbrook, Mahaning Heights\",\n",
    "    \"Ivy City, Arboretum, Trinidad, Carver Langston\": \"NE Ivy City, Arboretum, Trinidad, Carver Langston\",\n",
    "    \"Fairfax Village, Naylor Gardens, Hillcrest, Summit Park\": \"SE Fairfax Village, Naylor Gardens, Hillcrest, Summit Park\",\n",
    "    \"Near Southeast, Navy Yard\": \"SE Near Southeast, Navy Yard\",\n",
    "    \"Congress Heights, Bellevue, Washington Highlands\": \"SE Congress Heights, Bellevue, Washington Highlands\",\n",
    "    \"Sheridan, Barry Farm, Buena Vista\": \"SE Sheridan, Barry Farm, Buena Vista\",\n",
    "    \"Woodridge, Fort Lincoln, Gateway\": \"NE Woodridge, Fort Lincoln, Gateway\",\n",
    "    \"Woodland/Fort Stanton, Garfield Heights, Knox Hill\": \"SE Woodland/Fort Stanton, Garfield Heights, Knox Hill\",\n",
    "    \"Deanwood, Burrville, Grant Park, Lincoln Heights, Fairmont Heights\": \"NE Deanwood, Burrville, Grant Park, Lincoln Heights, Fairmont Heights\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db072c",
   "metadata": {},
   "source": [
    "Note the boolean flags here. I'm defining \"likely commercial\" as:  \n",
    "1. An entire home/apartment\n",
    "1. AND the host has 2 or more listings\n",
    "1. AND it's available more than 180 days/year.  \n",
    "\n",
    "Could change those. Probably will, just to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f996db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price column dtype: float64\n",
      "\n",
      "Neighbourhoods: ['SE Historic Anacostia'\n",
      " 'NE/NW Edgewood, Bloomingdale, Truxton Circle, Eckington'\n",
      " 'NW-mid Columbia Heights, Mt. Pleasant, Pleasant Plains, Park View'\n",
      " 'NW-mid Brightwood Park, Crestwood, Petworth'\n",
      " 'SE Capitol Hill, Lincoln Park' 'NW-mid Takoma, Brightwood, Manor Park'\n",
      " 'NE Ivy City, Arboretum, Trinidad, Carver Langston'\n",
      " 'NW-far Friendship Heights, American University Park, Tenleytown'\n",
      " 'NW-mid Kalorama Heights, Adams Morgan, Lanier Heights'\n",
      " 'NW-mid Shaw, Logan Circle'\n",
      " 'NW-far Spring Valley, Palisades, Wesley Heights, Foxhall Crescent, Foxhall Village, Georgetown Reservoir'\n",
      " 'NW-far Cathedral Heights, McLean Gardens, Glover Park'\n",
      " 'SE Congress Heights, Bellevue, Washington Highlands'\n",
      " 'NW-mid West End, Foggy Bottom, GWU'\n",
      " 'NW-mid Colonial Village, Shepherd Park, North Portal Estates'\n",
      " 'NE Brookland, Brentwood, Langdon'\n",
      " 'NE/NW Lamont Riggs, Queens Chapel, Fort Totten, Pleasant Hill'\n",
      " 'NE Union Station, Stanton Park, Kingman Park'\n",
      " 'NW-mid Dupont Circle, Connecticut Avenue/K Street'\n",
      " 'NW-mid Howard University, Le Droit Park, Cardozo/Shaw'\n",
      " 'NW-far Georgetown, Burleith/Hillandale'\n",
      " 'SE Capitol View, Marshall Heights, Benning Heights'\n",
      " 'SW Southwest Employment Area, Southwest/Waterfront, Fort McNair, Buzzard Point'\n",
      " 'NW-far Hawthorne, Barnaby Woods, Chevy Chase'\n",
      " 'NE North Michigan Park, Michigan Park, University Heights'\n",
      " 'NW-far North Cleveland Park, Forest Hills, Van Ness'\n",
      " 'SE Douglas, Shipley Terrace'\n",
      " 'NW-far Cleveland Park, Woodley Park, Massachusetts Avenue Heights, Woodland-Normanstone Terrace'\n",
      " 'NW-mid Downtown, Chinatown, Penn Quarters, Mount Vernon Square, North Capitol Street'\n",
      " 'NE Deanwood, Burrville, Grant Park, Lincoln Heights, Fairmont Heights'\n",
      " 'NE Mayfair, Hillbrook, Mahaning Heights'\n",
      " 'SE Fairfax Village, Naylor Gardens, Hillcrest, Summit Park'\n",
      " 'NE/SE River Terrace, Benning, Greenway, Dupont Park'\n",
      " 'SE Near Southeast, Navy Yard'\n",
      " 'SE Twining, Fairlawn, Randle Highlands, Penn Branch, Fort Davis Park, Fort Dupont'\n",
      " 'SE Sheridan, Barry Farm, Buena Vista' 'NE Eastland Gardens, Kenilworth'\n",
      " 'SE Woodland/Fort Stanton, Garfield Heights, Knox Hill'\n",
      " 'NE Woodridge, Fort Lincoln, Gateway']\n",
      "\n",
      "License types: ['No License' 'Licensed' 'Exempt']\n",
      "\n",
      "Number of unique neighbourhoods: 39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clean and normalize key columns in the Airbnb listings DataFrame.\n",
    "\n",
    "- Cleans the 'price' column by removing currency symbols and commas, converting to float.\n",
    "- Standardizes neighborhood names using a mapping dictionary.\n",
    "- Cleans and categorizes the 'license' column into standardized categories.\n",
    "- Adds boolean columns for common analysis flags:\n",
    "    - is_entire_home: True if listing is an entire home/apartment.\n",
    "    - is_multi_listing_host: True if host has 2 or more listings.\n",
    "    - is_high_availability: True if listing is available more than 180 days/year.\n",
    "    - likely_commercial: True if listing meets all three criteria above.\n",
    "- Prints summary information about cleaned columns and unique values.\n",
    "\"\"\"\n",
    "\n",
    "# clean price column\n",
    "listings_raw.price = (\n",
    "    listings_raw.price.str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    ")\n",
    "\n",
    "# rename neighborhoods\n",
    "listings_raw[\"neighbourhood_cleansed\"] = listings_raw.neighbourhood_cleansed.replace(\n",
    "    neighbourhoods_dict\n",
    ")\n",
    "\n",
    "\n",
    "# categorizing license status\n",
    "# Hosted License: 5007242201001033 => Hosted License\n",
    "def clean_license_column(series):\n",
    "    def categorize_license(license):\n",
    "        if pd.isna(license) or not str(license).strip():\n",
    "            return \"No License\"\n",
    "        license_clean = str(license).split(\":\")[0].strip().lower()\n",
    "        if license_clean in [\"hosted license\", \"unhosted license\"]:\n",
    "            return \"Licensed\"\n",
    "        elif license_clean == \"exempt\":\n",
    "            return \"Exempt\"\n",
    "        else:\n",
    "            return \"No License\"\n",
    "\n",
    "    return series.apply(categorize_license)\n",
    "\n",
    "\n",
    "# replace license column with cleaned/categorized values\n",
    "listings_raw[\"license\"] = clean_license_column(listings_raw[\"license\"])\n",
    "\n",
    "# add booleans for likely commercial listings\n",
    "listings_raw[\"is_entire_home\"] = listings_raw[\"room_type\"] == \"Entire home/apt\"\n",
    "listings_raw[\"is_multi_listing_host\"] = (\n",
    "    listings_raw[\"calculated_host_listings_count\"] >= 2\n",
    ")\n",
    "listings_raw[\"is_high_availability\"] = listings_raw[\"availability_365\"] > 180\n",
    "listings_raw[\"likely_commercial\"] = (\n",
    "    listings_raw[\"is_entire_home\"]\n",
    "    & listings_raw[\"is_high_availability\"]\n",
    "    & listings_raw[\"is_multi_listing_host\"]\n",
    ")\n",
    "\n",
    "# check output\n",
    "print(f\"Price column dtype: {listings_raw.price.dtype}\\n\")\n",
    "print(f\"Neighbourhoods: {listings_raw.neighbourhood_cleansed.unique()}\\n\")\n",
    "print(f\"License types: {listings_raw.license.unique()}\\n\")\n",
    "print(\n",
    "    f\"Number of unique neighbourhoods: {len(listings_raw.neighbourhood_cleansed.unique())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare cleaned listings dataframe\n",
    "listings_clean = listings_raw[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"host_id\",\n",
    "        \"quarter\",\n",
    "        \"quarter_index\",\n",
    "        \"neighbourhood_cleansed\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"price\",\n",
    "        \"room_type\",\n",
    "        \"minimum_nights\",\n",
    "        \"availability_365\",\n",
    "        \"calculated_host_listings_count\",\n",
    "        \"license\",\n",
    "        \"is_entire_home\",\n",
    "        \"is_multi_listing_host\",\n",
    "        \"is_high_availability\",\n",
    "        \"likely_commercial\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# rename columns\n",
    "listings_clean = listings_clean.rename(\n",
    "    columns={\"id\": \"listing_id\", \"neighbourhood_cleansed\": \"neighborhood\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26b1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings: 62204\n"
     ]
    }
   ],
   "source": [
    "# load listings_clean into PostgreSQL\n",
    "to_sql_and_csv(\"listings_long\", listings_clean)\n",
    "\n",
    "# check it worked\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT COUNT(*) FROM listings_long\")\n",
    "    result = conn.execute(query)\n",
    "print(f\"Number of listings: {result.fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80168b9b",
   "metadata": {},
   "source": [
    "### Calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc418c2",
   "metadata": {},
   "source": [
    "N.B. - Calendar for June of 2025 is blank. Data unavialable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b945773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2023_jun with 2387122 rows.\n",
      "Loaded 2023_sep with 2447281 rows.\n",
      "Loaded 2023_dec with 2500945 rows.\n",
      "Loaded 2024_mar with 1650480 rows.\n",
      "Loaded 2024_jun with 1798300 rows.\n",
      "Loaded 2024_sep with 1990300 rows.\n",
      "Loaded 2024_dec with 2176398 rows.\n",
      "Loaded 2025_mar with 2282941 rows.\n",
      "Loaded 2025_jun with 0 rows.\n",
      "Loaded 2025_sep with 2329437 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johbr\\AppData\\Local\\Temp\\ipykernel_24736\\3529734324.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (19563204, 9)\n",
      "Columns: ['listing_id', 'date', 'available', 'price', 'adjusted_price', 'minimum_nights', 'maximum_nights', 'quarter', 'quarter_index']\n",
      "Missing columns by quarter:\n",
      "2023_jun: {'quarter_index', 'quarter'}\n",
      "2023_sep: {'quarter_index', 'quarter'}\n",
      "2023_dec: {'quarter_index', 'quarter'}\n",
      "2024_mar: {'quarter_index', 'quarter'}\n",
      "2024_jun: {'quarter_index', 'quarter'}\n",
      "2024_sep: {'quarter_index', 'quarter'}\n",
      "2024_dec: {'quarter_index', 'quarter'}\n",
      "2025_mar: {'quarter_index', 'quarter'}\n",
      "2025_jun: {'quarter_index', 'quarter'}\n",
      "2025_sep: {'quarter_index', 'quarter'}\n"
     ]
    }
   ],
   "source": [
    "# load calendar data\n",
    "calendar_raw = load_quarterly_csv(\"calendar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcf581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in calendar_summary: 53606\n",
      "Number of rows in PostgreSQL calendar_summary: 53606\n",
      "(3344, '2025_Q3', 9, Decimal('0.9917808219178083'), Decimal('99.17808219178083'), Decimal('362'))\n",
      "(3686, '2023_Q2', 0, Decimal('0.7589041095890411'), Decimal('75.89041095890411'), Decimal('261'))\n",
      "(3686, '2023_Q3', 1, Decimal('0.7424657534246575'), Decimal('74.24657534246575'), Decimal('271'))\n",
      "(3686, '2023_Q4', 2, Decimal('1.0'), Decimal('100.0'), Decimal('365'))\n",
      "(3686, '2024_Q1', 3, Decimal('1.0'), Decimal('100.0'), Decimal('365'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Summarizes Airbnb calendar data and loads results into PostgreSQL.\n",
    "\n",
    "- Converts the 'available' column from 't'/'f' to 1/0 for numeric analysis.\n",
    "- Groups by listing, quarter, and quarter_index to compute:\n",
    "    - mean_available_days: Average availability per listing per quarter.\n",
    "    - pct_days_available: Percentage of days available per listing per quarter.\n",
    "    - max_consecutive_available_days: Maximum consecutive available days per listing per quarter.\n",
    "- Loads the summary DataFrame into the 'calendar_summary' table in PostgreSQL.\n",
    "- Verifies successful load by checking row count and previewing sample rows from the database.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def max_consecutive_available(arr):\n",
    "    # arr: 1D array of 0/1\n",
    "    max_count = count = 0\n",
    "    for val in arr:\n",
    "        if val == 1:\n",
    "            count += 1\n",
    "            max_count = max(max_count, count)\n",
    "        else:\n",
    "            count = 0\n",
    "    return max_count\n",
    "\n",
    "\n",
    "# convert available from t/f to 1/0 boolean\n",
    "calendar_raw[\"available\"] = (\n",
    "    calendar_raw[\"available\"]\n",
    "    .map({\"t\": 1, \"f\": 0})\n",
    "    .fillna(calendar_raw[\"available\"])\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# summarize availability by listing and quarter\n",
    "calendar_summary = (\n",
    "    calendar_raw.sort_values([\"listing_id\", \"quarter\", \"date\"])\n",
    "    .groupby([\"listing_id\", \"quarter\", \"quarter_index\"])\n",
    "    .agg(\n",
    "        mean_available_days=(\"available\", \"mean\"),\n",
    "        pct_days_available=(\"available\", lambda x: x.mean() * 100),\n",
    "        max_consecutive_available_days=(\n",
    "            \"available\",\n",
    "            lambda x: max_consecutive_available(x.values),\n",
    "        ),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"Number of rows in calendar_summary: {len(calendar_summary)}\")\n",
    "\n",
    "# load calendar_summary into database\n",
    "to_sql_and_csv(\"calendar_summary\", calendar_summary)\n",
    "\n",
    "# check it worked\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT COUNT(*) FROM calendar_summary\")\n",
    "    result = conn.execute(query)\n",
    "print(f\"Number of rows in PostgreSQL calendar_summary: {result.fetchone()[0]}\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM calendar_summary LIMIT 5\")\n",
    "    result = conn.execute(query)\n",
    "    for row in result.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796b902",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752eb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in reviews_summary: 62204\n",
      "Number of rows in PostgreSQL reviews_summary: 62204\n",
      "(3686, '2023_Q2', 0, 82, 3, 0, Decimal('0.53'), datetime.date(2010, 11, 1), datetime.date(2023, 3, 8))\n",
      "(3943, '2023_Q2', 0, 472, 31, 2, Decimal('2.75'), datetime.date(2009, 5, 10), datetime.date(2023, 5, 24))\n",
      "(883653, '2023_Q2', 0, 35, 2, 0, Decimal('0.28'), datetime.date(2013, 4, 1), datetime.date(2022, 10, 10))\n",
      "(153545, '2023_Q2', 0, 38, 1, 0, Decimal('0.27'), datetime.date(2011, 9, 15), datetime.date(2022, 6, 21))\n",
      "(4197, '2023_Q2', 0, 53, 8, 1, Decimal('0.31'), datetime.date(2009, 5, 14), datetime.date(2023, 5, 27))\n"
     ]
    }
   ],
   "source": [
    "# prepare reviews_summary\n",
    "reviews_summary = listings_raw[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"quarter\",\n",
    "        \"quarter_index\",\n",
    "        \"number_of_reviews\",\n",
    "        \"number_of_reviews_ltm\",\n",
    "        \"number_of_reviews_l30d\",\n",
    "        \"reviews_per_month\",\n",
    "        \"first_review\",\n",
    "        \"last_review\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "reviews_summary = reviews_summary.rename(\n",
    "    columns={\n",
    "        \"id\": \"listing_id\",\n",
    "        \"number_of_reviews\": \"reviews_count\",\n",
    "        \"number_of_reviews_ltm\": \"reviews_count_ltm\",\n",
    "        \"number_of_reviews_l30d\": \"reviews_count_l30d\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Number of rows in reviews_summary: {len(reviews_summary)}\")\n",
    "\n",
    "# load review summary into PostgreSQL\n",
    "to_sql_and_csv(\"reviews_summary\", reviews_summary)\n",
    "\n",
    "# check it loaded\n",
    "# check it worked\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT COUNT(*) FROM reviews_summary\")\n",
    "    result = conn.execute(query)\n",
    "print(f\"Number of rows in PostgreSQL reviews_summary: {result.fetchone()[0]}\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    query = text(\"SELECT * FROM reviews_summary LIMIT 5\")\n",
    "    result = conn.execute(query)\n",
    "    for row in result.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c279ad",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- [Back to Top](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4df85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
